# Social Media Content for Swarm

## Twitter/X Posts (Copy-Paste Ready)

### Post 1: Launch Announcement
```
ğŸ Just shipped Swarm - turn your homelab into an AI supercomputer

Pool your Mac, Pi, and old laptops together. Run LLMs that won't fit on one device.

âœ… Zero config (mDNS auto-discovery)
âœ… Plug & play setup
âœ… Works on Mac/Linux/RPi

Open source, MIT license

https://github.com/neilyneilynig/swarm
```

### Post 2: Problem/Solution
```
You: Have 28GB RAM across 3 devices ğŸ’»ğŸ“±ğŸ–¥ï¸
Also you: Can't run llama-13b (needs 26GB)

Swarm: "Hold my distributed layers"

Pools devices â†’ partitions model â†’ runs inference

From 0 to AI cluster in 2 minutes.

https://github.com/neilyneilynig/swarm
```

### Post 3: Technical Deep Dive
```
How Swarm works:

1ï¸âƒ£ mDNS discovery (nodes find each other)
2ï¸âƒ£ Memory-based partitioning (intelligent layer distribution)
3ï¸âƒ£ Coordinator routes inference
4ï¸âƒ£ Async tensor transfer

Built with Python + Rich for beautiful terminal UI

Check out the demos ğŸ‘‡
https://github.com/neilyneilynig/swarm/tree/master/demos
```

### Post 4: Use Case
```
Real homelab setup:

â€¢ MacBook Pro M1: 16GB
â€¢ Raspberry Pi 5: 8GB  
â€¢ Old Mac Mini: 4GB

Combined: 28GB cluster

Can run: llama-13b, mistral-7b, llama-70b (4-bit)
Setup time: < 2 minutes
Cloud costs: $0

https://github.com/neilyneilynig/swarm
```

### Post 5: Call for Contributors
```
Swarm is open source and looking for contributors! ğŸ

Next up:
â€¢ Real PyTorch/MLX model loading
â€¢ GPU acceleration (Metal/CUDA)
â€¢ Quantization support
â€¢ Web dashboard

Built in public. PRs welcome.

https://github.com/neilyneilynig/swarm
```

---

## LinkedIn Posts

### Professional Announcement
```
Excited to announce Swarm ğŸ - an open-source distributed AI inference framework!

The challenge: Modern LLMs require 20-100GB+ RAM, but most people have multiple consumer devices with 4-16GB each.

The solution: Pool resources across devices with zero-config setup.

Key innovations:
âœ“ mDNS-based auto-discovery
âœ“ Memory-proportional layer partitioning  
âœ“ Async coordination architecture
âœ“ Cross-platform (Mac/Linux/Raspberry Pi)

Built from scratch in Python. Alpha stage but functional.

Perfect for researchers, educators, and anyone exploring distributed systems.

MIT licensed. Contributions welcome.

GitHub: https://github.com/neilyneilynig/swarm

#OpenSource #MachineLearning #DistributedSystems #AI
```

---

## Reddit Title Templates

### r/selfhosted
**[Project] Swarm - Pool your homelab devices for distributed AI inference (Mac/Linux/Pi)**

### r/LocalLLaMA  
**Built a distributed inference tool - run LLMs across multiple devices with zero config**

### r/raspberry_pi
**Turn your Pi cluster into an AI inference node - distributed LLM setup in 2 minutes**

### r/homelab
**[OC] Swarm - distributed AI inference across your existing hardware (no new purchases needed)**

### r/MachineLearning
**[P] Swarm: Zero-config distributed LLM inference for consumer hardware**

---

## Instagram Caption
```
ğŸ Turn unused hardware into an AI cluster

Got old devices collecting dust? Pool them for distributed AI inference.

Swarm makes it stupid simple:
â†’ Install on each device
â†’ Nodes auto-discover
â†’ Run LLMs that won't fit on one machine

Zero config. Plug & play. Open source.

Built for homelabbers, hackers, and tinkerers.

Link in bio ğŸ”—

#AI #MachineLearning #OpenSource #Homelab #RaspberryPi #Tech #Coding #Python #SideProject #DevLife
```

---

## YouTube Video Titles

1. **"I Turned My Homelab Into an AI Supercomputer (Zero Config)"**
2. **"Distributed AI Inference on Consumer Hardware - Swarm Tutorial"**
3. **"Run LLMs on Mac + Raspberry Pi - Distributed Inference Demo"**
4. **"Building a DIY AI Cluster from Spare Hardware"**
5. **"Swarm: Open Source Distributed AI (Better Than Cloud?)"**

---

## YouTube Description Template
```
ğŸ Swarm - Distributed AI Inference for Homelabs

Turn your unused devices into an AI cluster. Run LLMs across Mac, Linux, and Raspberry Pi with zero configuration.

ğŸ”— LINKS
GitHub: https://github.com/neilyneilynig/swarm
Portfolio: https://neilyneilynig.github.io
Documentation: https://github.com/neilyneilynig/swarm/blob/master/DEMO.md

â±ï¸ TIMESTAMPS
0:00 - Intro
0:30 - The Problem
1:00 - How Swarm Works
2:00 - Installation Demo
4:00 - Running Inference
5:30 - Technical Details
6:30 - Call to Action

ğŸ› ï¸ MY SETUP
â€¢ MacBook Pro M1 (16GB)
â€¢ Raspberry Pi 5 (8GB)
â€¢ Mac Mini (4GB)
â€¢ Total: 28GB cluster

ğŸ“Š FEATURES
âœ“ mDNS auto-discovery
âœ“ Automatic layer partitioning
âœ“ CLI + Python API
âœ“ Works on Mac/Linux/Pi
âœ“ MIT license

ğŸš€ STATUS
Alpha - Core features working, real model loading coming soon

ğŸ’¬ SOCIALS
Twitter: @[your handle]
GitHub: https://github.com/neilyneilynig
Email: nelsicles@gmail.com

#AI #MachineLearning #DistributedSystems #Homelab #RaspberryPi #OpenSource
```

---

## Discord/Slack Server Description
```
ğŸ **Swarm Community**

Distributed AI inference for consumer hardware. Pool your Mac, Linux, and Raspberry Pi devices to run LLMs.

**What is Swarm?**
Zero-config distributed inference framework. Nodes auto-discover, model layers partition automatically, inference coordinates across devices.

**Channels:**
â€¢ #announcements - Updates and releases
â€¢ #general - General discussion
â€¢ #help - Setup and troubleshooting
â€¢ #development - Contribute to Swarm
â€¢ #showcase - Show off your cluster

**Links:**
â€¢ GitHub: https://github.com/neilyneilynig/swarm
â€¢ Docs: https://github.com/neilyneilynig/swarm/blob/master/DEMO.md

Open source. MIT licensed. Built in public.
```

---

## GitHub Topics/Tags

Add these to maximize discoverability:

```
ai
machine-learning  
distributed-systems
llm
inference
pytorch
raspberry-pi
homelab
edge-computing
peer-to-peer
mDNS
zero-config
multi-device
distributed-inference
local-ai
self-hosted
consumer-hardware
mac
linux
python
```

---

## One-Liners for Sharing

1. **"Turn your homelab into an AI supercomputer with Swarm ğŸ"**

2. **"Pool your devices, run bigger models. Zero config."**

3. **"Distributed AI inference for consumer hardware - setup in 2 minutes"**

4. **"Got spare devices? Now you have an AI cluster."**

5. **"Open source distributed LLM inference. Works on what you already own."**

6. **"Mac + Pi + old laptop = AI cluster. Thanks, Swarm."**

7. **"Zero-config distributed inference. Just works.â„¢"**

8. **"Run LLMs that won't fit on one device. Pool resources with Swarm."**

9. **"Homelab AI without the cloud bills ğŸ"**

10. **"Distributed inference, but make it simple."**

---

## Email Newsletter Blurb

```
Subject: Introducing Swarm ğŸ - Distributed AI for Your Homelab

Hey [Name],

Just shipped something I think you'll like: Swarm - distributed AI inference for consumer hardware.

**The problem:** You have a Mac (16GB), a Pi (4GB), maybe an old laptop. Individually, none can run modern LLMs. Together? They have 20-40GB.

**The solution:** Swarm pools them automatically. Zero config, plug & play.

Setup on each device:
```
git clone swarm
pip install -e .
swarm node
```

That's it. Nodes find each other, partition the model, coordinate inference.

Alpha stage, but functional. Built from scratch, open source, MIT license.

Check it out: https://github.com/neilyneilynig/swarm

Would love your feedback!

Neil
```

---

## Product Hunt Launch Copy

**Tagline:**  
"Turn your homelab into an AI supercomputer - distributed LLM inference with zero config"

**Description:**  
Pool computing resources across multiple consumer devices (Mac, Linux, Raspberry Pi) to run large language models. Auto-discovery via mDNS, automatic layer partitioning, CLI and Python API. Open source, MIT licensed.

**What problem does it solve?**  
Modern LLMs need 20-100GB+ RAM, but most people have multiple devices with 4-16GB each sitting idle. Swarm pools them into a cluster so you can run models that won't fit on any single device.

**How is it different?**  
Zero configuration required. No manual IP/port setup. No cloud costs. Works with hardware you already own. Built for homelabbers and hackers.

**Maker Comment:**  
"Built this because I had a Mac, Pi, and old laptop gathering dust. Each alone couldn't run llama-13b, but together they could. Wanted something that 'just works' - type one command, nodes find each other. Alpha but functional. Real model loading coming soon!"
